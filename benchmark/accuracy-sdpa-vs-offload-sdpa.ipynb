{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae7b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xformers.ops.fmha import (\n",
    "    memory_efficient_attention_forward,\n",
    "    memory_efficient_attention_backward, \n",
    "    memory_efficient_attention_partial,\n",
    "    merge_attentions\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6b0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(1, 21, 2, 128).cuda().to(torch.bfloat16)\n",
    "k = torch.randn(1, 21, 100, 128).cuda().to(torch.bfloat16)\n",
    "v = torch.randn(1, 21, 100, 128).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011522e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 ms, sys: 4.53 ms, total: 6.2 ms\n",
      "Wall time: 4.55 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 2, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out_dot = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "out_dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c54ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 21, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ = q.transpose(1, 2)\n",
    "k_ = k.transpose(1, 2)\n",
    "v_ = v.transpose(1, 2)\n",
    "v_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3271f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 5 # means we split attention into 5 partitions and incrementally calculate it\n",
    "k_chunks = k_.chunk(partition_size, dim = 1)\n",
    "v_chunks = v_.chunk(partition_size, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29544ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 ms, sys: 44.6 ms, total: 69.4 ms\n",
      "Wall time: 67.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 2, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://github.com/ScalingIntelligence/hydragen/blob/main/hydragen/attention.py#L21\n",
    "outs, lses = [], []\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(q_, k_chunks[i], v_chunks[i])\n",
    "    outs.append(out_)\n",
    "    lses.append(lse_)\n",
    "    \n",
    "outs = torch.stack(outs)\n",
    "lses = torch.stack(lses)\n",
    "\n",
    "max_lse = lses.max(0).values\n",
    "\n",
    "adjust_factors = (lses - max_lse[None]).exp()\n",
    "adjust_factors = adjust_factors.transpose(2, 3).unsqueeze(-1)\n",
    "new_denominator = adjust_factors.sum(0)\n",
    "out_offload = ((outs * adjust_factors).sum(0) / new_denominator).transpose(1, 2)\n",
    "out_offload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f1955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.2345e-03, -2.4971e-04, -6.6012e-04,  ..., -2.1459e-04,\n",
       "            3.7201e-04, -1.3451e-04],\n",
       "          [-7.3791e-05, -3.8874e-04, -3.0696e-04,  ..., -5.2631e-05,\n",
       "            6.5991e-04, -8.1521e-04]],\n",
       "\n",
       "         [[ 3.0283e-04, -8.0040e-04,  3.8594e-04,  ...,  1.2854e-04,\n",
       "            3.9496e-04,  7.4293e-05],\n",
       "          [-1.1277e-04,  5.5200e-04, -6.7055e-04,  ..., -2.2515e-04,\n",
       "           -6.5799e-04,  3.8579e-05]],\n",
       "\n",
       "         [[-5.3185e-04,  4.1805e-05, -7.8999e-05,  ..., -1.3923e-04,\n",
       "            3.5194e-04, -2.9349e-04],\n",
       "          [-1.7911e-04,  4.5266e-04, -3.9779e-04,  ..., -1.9804e-05,\n",
       "            2.9813e-04, -7.9170e-05]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.3151e-04,  1.2643e-04,  1.1572e-03,  ..., -1.8989e-04,\n",
       "           -8.5682e-08,  9.7290e-05],\n",
       "          [ 6.8823e-04,  9.1299e-04,  1.8278e-04,  ...,  2.0218e-04,\n",
       "            8.0469e-04,  1.2076e-04]],\n",
       "\n",
       "         [[-2.3107e-04,  7.3041e-04, -3.1593e-04,  ..., -6.9819e-05,\n",
       "            3.9328e-05, -5.7943e-04],\n",
       "          [ 2.3900e-04,  3.2842e-05, -2.3440e-04,  ...,  6.3497e-04,\n",
       "           -2.0912e-04, -1.1136e-03]],\n",
       "\n",
       "         [[ 5.8937e-04,  5.5403e-05,  4.0304e-04,  ...,  8.4704e-04,\n",
       "            5.2333e-05,  6.2153e-05],\n",
       "          [ 8.2231e-04, -3.2361e-04, -2.8256e-04,  ...,  2.1887e-04,\n",
       "            2.4678e-04,  8.3281e-05]]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out_offload - out_dot) # the difference should be super small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2788c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
