{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae7b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xformers.ops.fmha import (\n",
    "    memory_efficient_attention_forward,\n",
    "    memory_efficient_attention_backward, \n",
    "    memory_efficient_attention_partial,\n",
    "    merge_attentions\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6b0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(1, 21, 2, 128).cuda().to(torch.bfloat16)\n",
    "k = torch.randn(1, 21, 100, 128).cuda().to(torch.bfloat16)\n",
    "v = torch.randn(1, 21, 100, 128).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "011522e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 ms, sys: 953 Âµs, total: 2.97 ms\n",
      "Wall time: 2.41 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 2, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out_dot = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "out_dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c54ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 21, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ = q.transpose(1, 2)\n",
    "k_ = k.transpose(1, 2)\n",
    "v_ = v.transpose(1, 2)\n",
    "v_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3271f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 5 # means we split attention into 5 partitions and incrementally calculate it\n",
    "k_chunks = k_.chunk(partition_size, dim = 1)\n",
    "v_chunks = v_.chunk(partition_size, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29544ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.6 ms, sys: 23.1 ms, total: 41.6 ms\n",
      "Wall time: 40.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 2, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://github.com/ScalingIntelligence/hydragen/blob/main/hydragen/attention.py#L21\n",
    "outs, lses = [], []\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(q_, k_chunks[i], v_chunks[i])\n",
    "    outs.append(out_)\n",
    "    lses.append(lse_)\n",
    "    \n",
    "outs = torch.stack(outs)\n",
    "lses = torch.stack(lses)\n",
    "\n",
    "max_lse = lses.max(0).values\n",
    "\n",
    "adjust_factors = (lses - max_lse[None]).exp()\n",
    "adjust_factors = adjust_factors.transpose(2, 3).unsqueeze(-1)\n",
    "new_denominator = adjust_factors.sum(0)\n",
    "out_offload = ((outs * adjust_factors).sum(0) / new_denominator).transpose(1, 2)\n",
    "out_offload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f1955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.1083e-04,  4.6998e-04, -2.2201e-04,  ...,  1.3250e-04,\n",
       "           -9.2015e-05, -2.4086e-04],\n",
       "          [ 4.1917e-05,  7.1779e-04, -4.3038e-04,  ..., -3.1373e-04,\n",
       "            5.4985e-06,  4.5154e-04]],\n",
       "\n",
       "         [[ 3.6941e-04, -1.3298e-03,  8.3983e-05,  ...,  6.5812e-04,\n",
       "           -3.7771e-04,  1.7650e-05],\n",
       "          [ 7.5035e-04,  7.2541e-05,  7.7300e-05,  ..., -8.0094e-04,\n",
       "            3.4310e-04, -3.7353e-04]],\n",
       "\n",
       "         [[ 1.7822e-05,  6.1104e-04, -1.4340e-04,  ...,  8.2256e-04,\n",
       "           -5.3018e-04,  3.2209e-04],\n",
       "          [ 3.9487e-04, -1.3969e-04,  3.4460e-04,  ...,  1.7525e-04,\n",
       "            3.3581e-04,  6.3409e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.8189e-04, -4.5300e-05,  3.0844e-04,  ..., -2.3700e-04,\n",
       "            2.8881e-04, -3.2416e-04],\n",
       "          [ 4.6875e-05,  5.4127e-04,  1.7814e-04,  ...,  4.4993e-04,\n",
       "            4.5493e-05, -7.7967e-04]],\n",
       "\n",
       "         [[ 3.9813e-04, -1.9488e-04,  4.2811e-04,  ..., -3.5535e-04,\n",
       "            1.0266e-03, -1.2019e-04],\n",
       "          [-2.6822e-04,  2.1163e-04, -5.8941e-04,  ...,  1.0998e-04,\n",
       "           -5.3141e-05,  1.1335e-04]],\n",
       "\n",
       "         [[-7.3358e-05,  5.8804e-04,  1.4591e-04,  ..., -4.2304e-04,\n",
       "           -6.0403e-04, -2.7254e-04],\n",
       "          [ 2.8828e-04,  2.6290e-04, -5.8039e-04,  ...,  3.3575e-04,\n",
       "            1.2501e-04,  2.2390e-04]]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out_offload - out_dot) # the difference should be super small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec2788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, max_lse = None, None\n",
    "new_denominator = None\n",
    "attn_output = None\n",
    "\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(q_, k_chunks[i], v_chunks[i])\n",
    "    lse_ = lse_.transpose(1, 2)\n",
    "\n",
    "    if i == 0:\n",
    "        max_lse = lse_\n",
    "        adjust_factors = torch.ones_like(lse_).unsqueeze(-1)\n",
    "        new_denominator = adjust_factors\n",
    "        attn_output = out_ * adjust_factors\n",
    "    else:\n",
    "        new_max_lse = torch.maximum(max_lse, lse_)\n",
    "        \n",
    "        old_adjust_factors = torch.exp(max_lse - new_max_lse).unsqueeze(-1)\n",
    "        new_adjust_factors = torch.exp(lse_ - new_max_lse).unsqueeze(-1)\n",
    "        \n",
    "        new_denominator = old_adjust_factors * new_denominator + new_adjust_factors\n",
    "        attn_output = old_adjust_factors * attn_output + new_adjust_factors * out_\n",
    "        \n",
    "        max_lse = new_max_lse\n",
    "\n",
    "attn_output = attn_output / new_denominator\n",
    "attn_output = attn_output.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e4e6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3039e-08,  0.0000e+00, -1.4901e-08,  ...,  1.4901e-08,\n",
       "           -7.4506e-09,  0.0000e+00],\n",
       "          [ 0.0000e+00,  1.4901e-08,  0.0000e+00,  ...,  2.2352e-08,\n",
       "            3.7253e-09,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            3.7253e-09,  0.0000e+00],\n",
       "          [ 0.0000e+00,  3.7253e-09,  7.4506e-09,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00, -1.8626e-09,  ..., -1.4901e-08,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  9.7789e-09,  0.0000e+00,  ...,  7.4506e-09,\n",
       "           -1.1176e-08, -1.4901e-08]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9802e-08,  0.0000e+00,  0.0000e+00,  ...,  7.4506e-09,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 1.8626e-08, -7.4506e-09, -1.4901e-08,  ...,  0.0000e+00,\n",
       "           -1.4901e-08,  0.0000e+00]],\n",
       "\n",
       "         [[ 1.4901e-08, -1.1176e-08, -2.9802e-08,  ...,  1.4901e-08,\n",
       "           -9.3132e-09,  1.4901e-08],\n",
       "          [-1.4901e-08,  0.0000e+00,  0.0000e+00,  ..., -1.4901e-08,\n",
       "            3.7253e-09,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00, -1.3039e-08,  ...,  2.2352e-08,\n",
       "            7.4506e-09, -1.4901e-08],\n",
       "          [ 0.0000e+00, -1.8626e-09,  0.0000e+00,  ..., -3.7253e-09,\n",
       "            0.0000e+00,  3.7253e-09]]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output - out_offload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
